---
title: 13.K-means Code
categories:
  - code_file
toc: true
---

[목적]
  - 비지도학습 중 하나인 Clustering 중 K-means Clustering 실습
  - ForLoop 활용 K의 Range를 변경 시켜가며 실습 진행
  - Clustering은 기본적으로 Data가 많을 때 시간이 굉장히 오래걸림
     - Distance Matrix를 만들고 행렬 계산을 하는 알고리즘이 많기 때문

[Process]
  1. Define X's
  2. Modeling
  
  ```python
  import gc
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import warnings
warnings.filterwarnings("ignore")

from sklearn.datasets import load_iris
from sklearn.cluster import KMeans
from sklearn.metrics import confusion_matrix, f1_score
from sklearn.preprocessing import MinMaxScaler
from sklearn.decomposition import PCA
```

[기존 Classification Data 활용]
  - Clustering 후 Label과 비교
  
 ```python
  #loading the iris dataset
data = load_iris()
```
- iris data 갖고 옴

 ```python
  # X's & Y Split
Y = pd.DataFrame(data['target'], columns = ['Target'])
X = pd.DataFrame(data['data'], columns = data['feature_names'])
```

 ```python
  data= pd.concat([X, Y], axis=1)
```
- x,y 나눌 필요 없어서 다시 합쳐줌 (axis=1, 열 기준 합쳐줌)

[Clustering 전 Scaling]
  - Clustering은 Distance를 구하는 작업이 필요함
  - Feature들의 Scale이 다르면 Distance를 구하는데 가중치가 들어가게 됨
  - 따라서, Distance 기반의 Clustering의 경우 Scaling이 필수
  
 ```python
  # Scaling
scaler = MinMaxScaler().fit(X)
X_scal = scaler.transform(X)
X_scal = pd.DataFrame(X_scal, columns=X.columns)
```

[차원축소]
  - Clustering의 결과를 확인하기 위하여 차원 축소 진행
  - 다음 Chapter에서 차원축소에 대해 자세히 설명할 예정
  
 ```python
  pca = PCA(n_components=2).fit(X)
X_PCA = pca.fit_transform(X)
X_EMM = pd.DataFrame(X_PCA, columns=['AXIS1','AXIS2'])
print(">>>> PCA Variance : {}".format(pca.explained_variance_ratio_))
```
- 4차원 -> 2차원 축소(PCA)

[K-means]
  - Hyperparameter Tuning using for Loop
[K-means Parameters]
  - Packge : https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html
  - n_clusters : Cluster 개수 (K)
  - n_init : Number of times the k-means algorithm is run with different centroid seeds
    - K-means는 Step2에서 '초기 중심점 설정'이라는 작업을 하는데, 초기 중심점을 셋팅하는 것에 따라 군집의 Quality가 달라짐
    - 따라서 여러번 시도해 보는것 
    - default = 10
  - max_iter : 몇번 Round를 진행할 것 인지
    - Round
       - Step 4: 중심점 재설정
       - Step 5: 데이터를 군집에 재할당
    - 이러한 Round를 최대 몇번까지 돌것인가?
    - default = 300
       - 300번 안에 중심점 움직임이 멈추지 않으면 그냥 STOP

 ```python
  # K-means Modeling
for cluster in list(range(2, 6)):
    Cluster = KMeans(n_clusters=cluster).fit(X_scal)
    labels = Cluster.predict(X_scal)

    # label Add to DataFrame
    data['{} label'.format(cluster)] = labels
    labels = pd.DataFrame(labels, columns=['labels'])
    # Plot Data Setting
    plot_data = pd.concat([X_EMM, labels], axis=1)
    groups = plot_data.groupby('labels')

    mar = ['o', '+', '*', 'D', ',', 'h', '1', '2', '3', '4', 's', '<', '>']
    colo = ['red', 'orange', 'green', 'blue', 'cyan', 'magenta', 'black', 'yellow', 'grey', 'orchid', 'lightpink']

    fig, ax = plt.subplots(figsize=(10,10))
    for j, (name, group) in enumerate(groups):
        ax.plot(group['AXIS1'], 
                group['AXIS2'], 
                marker=mar[j],
                linestyle='',
                label=name,
                c = colo[j],
                ms=10)
        ax.legend(fontsize=12, loc='upper right') # legend position
    plt.title('Scatter Plot', fontsize=20)
    plt.xlabel('AXIS1', fontsize=14)
    plt.ylabel('AXIS2', fontsize=14)
    plt.show()
    print("---------------------------------------------------------------------------------------------------")

    gc.collect()
```
- cluster(k): 2~5까지 반복
- 데이터 프레임에 label 붙여줌-> 나중에 plot 그리기 쉽게..
- X_EMM(2차원 축소)에다가도 label 붙여주기
- group by-> label대로 group 묶임
- enumerate(grups): groups의 수 만큼 튜플 형성 
	group 나눠진 수 만큼 for loop 돌게됨
- 각 그림은 2,3,4,5개로 각각 나눴을 때
![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240110144824.png?raw=true)
![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240110144844.png?raw=true)
![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240110144900.png?raw=true)
![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240110144932.png?raw=true)

 ```python
  # Confusion Matrix 확인
cm = confusion_matrix(data['Target'], data['3 label'])
print(cm)
```
-
	![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240110151634.png?raw=true)
	 해석: 대각선 값(50,47,36)이 정확히 분류한 것들
	 class1: 50/50개 정확히 분류
	 class2: 47/50개 정확히 분류
	 class3 36/50개 정확히 분류-> 다소 아쉽 