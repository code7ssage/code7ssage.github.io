---
title: 2-1. Regression Problem
categories:
  - machine_learning
toc: true
---

# Error?
- Error = Variance + Bias + Noise
- Variance: 추정 값(Algorithm Output)의 평균과 추정 값 (Algorithm Output) 들 간의 차이 
- Bias: 추정 값 (Algorithm Output) 의 평균과 참 값(True)들 간의 차이 
- Bias는 참 값과 추정 값의 거리를 의미. Variance는 추정 값들의 흩어진 정도를 의미함
	 - [Overfitting](https://code7ssage.github.io/key_terms/Overfitting/) : bias가 낮고, variance가 높은 상태
	 - 둘다 낮은 모델이 best
	![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240104124601.png?raw=true)
	 - model complexity가 올라가면 bias가 증가함
- [regression](https://code7ssage.github.io/key_terms/regression/) 종류는 참조
- 𝜷 추정 법
	- 공분산/분산
	![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240104125850.png?raw=true)
- 𝜷 검증 : [p-value](https://code7ssage.github.io/key_terms/p-value/)가 0.05 이하인지 확인 

# 모델 평가는 어떻게?
- 정성적인 방법
	- [R square](https://code7ssage.github.io/key_terms/R-square/) (R^2)값이 1에 가까울수록 좋음
- 정량적인 방법 
	1. Average Error – 평균오차 (잘못된 정량적인 방법)
	2. Mean Absolute Error ; [MAE](https://code7ssage.github.io/key_terms/MAE/) – 평균 절대 오차
	3. Mean Absolute Percentage Error; [MAPE](https://code7ssage.github.io/key_terms/MAPE/) – 평균 절대 비율 오차
	4. Mean Squared Error; [MSE](https://code7ssage.github.io/key_terms/MSE/)
	5. Root Mean Squared Error [RMSE](https://code7ssage.github.io/key_terms/RMSE/)

# Feature selection
- Feature Selection 종류
	- **Filter Method** : X’s와 Y의 Correlation, Chi-Square Test, Anova, Variance Inflation Factor 등 간단한 기법으로 Filtering 수행 
	- **Wrapper Method** : Forward Selection, Backward Elimination, Stepwise Selection을 활용한 Feature selection 
	- **Embedded Method** : Regularization Approach를 활용하여 Model이 스스로 Feature Selection을 진행하는 방법
	![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240104142958.png?raw=true)
### Supervised Variable Selection
1. Exhaustive Search (완전 탐색)
	2^p-1개의 경우의 수 다 따짐
	현실적으로 사용 불가
2. Forward Selection
	R^2값이 높은 것들을 차례로 추가 함
	변수 추가 했는데 정확도의 변화가 없으면 stop
3. Backward Elimination
	변수 다 넣고 시작 하나씩 제거
	R^2값이 변화 없을 때 stop
4. Stepwise Selection
	 2,3을 번갈아 가며 같이 씀

### Embedded Method(Penalty Term)

- 장점 
	- Wrapper Method와 같이 Features의 상호작용을 고려함 
	- 다른 방법 보다 상대적으로 시간을 Save할 수 있음 
	- Model이 Train하면서 Feature의 Subset을 찾아감
1. [Ridge Regression](https://code7ssage.github.io/key_terms/Ridge-Regression/)
	실습:[4-1. Linear regression](https://code7ssage.github.io/code_file/4-1.-Linear-regression/), [4-2. Regularized Model-Ridge Code](https://code7ssage.github.io/code_file/4-2.-Regularized-Model-Ridge-Code/)
2. [LASSO Regression](https://code7ssage.github.io/key_terms/LASSO-Regression/)
- Ridge와 LASSO 모두 t가 작아짐에 따라 (λ 가 커짐에 따라) 모든 계수의 크기가 감소함
- Ridge and Lasso 장단점
	실습: [5. Regularized Model-LASSO Code](https://code7ssage.github.io/code_file/5.-Regularized-Model-LASSO-Code/)
	![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240104145805.png?raw=true)
3. [ElasticNet](https://code7ssage.github.io/key_terms/ElasticNet/)
	실습: [6. Regularized Model-ElasticNet Code](https://code7ssage.github.io/code_file/6.-Regularized-Model-ElasticNet-Code/)