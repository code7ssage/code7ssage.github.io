---
title: 2-1. Regression Problem
categories:
  - machine_learning
toc: true
---

# Error?
- Error = Variance + Bias + Noise
- Variance: ì¶”ì • ê°’(Algorithm Output)ì˜ í‰ê· ê³¼ ì¶”ì • ê°’ (Algorithm Output) ë“¤ ê°„ì˜ ì°¨ì´ 
- Bias: ì¶”ì • ê°’ (Algorithm Output) ì˜ í‰ê· ê³¼ ì°¸ ê°’(True)ë“¤ ê°„ì˜ ì°¨ì´ 
- BiasëŠ” ì°¸ ê°’ê³¼ ì¶”ì • ê°’ì˜ ê±°ë¦¬ë¥¼ ì˜ë¯¸. VarianceëŠ” ì¶”ì • ê°’ë“¤ì˜ í©ì–´ì§„ ì •ë„ë¥¼ ì˜ë¯¸í•¨
	 - [Overfitting](https://code7ssage.github.io/key_terms/Overfitting/) : biasê°€ ë‚®ê³ , varianceê°€ ë†’ì€ ìƒíƒœ
	 - ë‘˜ë‹¤ ë‚®ì€ ëª¨ë¸ì´ best
	![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240104124601.png?raw=true)
	 - model complexityê°€ ì˜¬ë¼ê°€ë©´ biasê°€ ì¦ê°€í•¨
- [regression](https://code7ssage.github.io/key_terms/regression/) ì¢…ë¥˜ëŠ” ì°¸ì¡°
- ğœ· ì¶”ì • ë²•
	- ê³µë¶„ì‚°/ë¶„ì‚°
	![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240104125850.png?raw=true)
- ğœ· ê²€ì¦ : [p-value](https://code7ssage.github.io/key_terms/p-value/)ê°€ 0.05 ì´í•˜ì¸ì§€ í™•ì¸ 

# ëª¨ë¸ í‰ê°€ëŠ” ì–´ë–»ê²Œ?
- ì •ì„±ì ì¸ ë°©ë²•
	- [R square](https://code7ssage.github.io/key_terms/R-square/) (R^2)ê°’ì´ 1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ
- ì •ëŸ‰ì ì¸ ë°©ë²• 
	1. Average Error â€“ í‰ê· ì˜¤ì°¨ (ì˜ëª»ëœ ì •ëŸ‰ì ì¸ ë°©ë²•)
	2. Mean Absolute Error ; [MAE](https://code7ssage.github.io/key_terms/MAE/) â€“ í‰ê·  ì ˆëŒ€ ì˜¤ì°¨
	3. Mean Absolute Percentage Error; [MAPE](https://code7ssage.github.io/key_terms/MAPE/) â€“ í‰ê·  ì ˆëŒ€ ë¹„ìœ¨ ì˜¤ì°¨
	4. Mean Squared Error; [MSE](https://code7ssage.github.io/key_terms/MSE/)
	5. Root Mean Squared Error [RMSE](https://code7ssage.github.io/key_terms/RMSE/)

# Feature selection
- Feature Selection ì¢…ë¥˜
	- **Filter Method** : Xâ€™sì™€ Yì˜ Correlation, Chi-Square Test, Anova, Variance Inflation Factor ë“± ê°„ë‹¨í•œ ê¸°ë²•ìœ¼ë¡œ Filtering ìˆ˜í–‰ 
	- **Wrapper Method** : Forward Selection, Backward Elimination, Stepwise Selectionì„ í™œìš©í•œ Feature selection 
	- **Embedded Method** : Regularization Approachë¥¼ í™œìš©í•˜ì—¬ Modelì´ ìŠ¤ìŠ¤ë¡œ Feature Selectionì„ ì§„í–‰í•˜ëŠ” ë°©ë²•
	![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240104142958.png?raw=true)
### Supervised Variable Selection
1. Exhaustive Search (ì™„ì „ íƒìƒ‰)
	2^p-1ê°œì˜ ê²½ìš°ì˜ ìˆ˜ ë‹¤ ë”°ì§
	í˜„ì‹¤ì ìœ¼ë¡œ ì‚¬ìš© ë¶ˆê°€
2. Forward Selection
	R^2ê°’ì´ ë†’ì€ ê²ƒë“¤ì„ ì°¨ë¡€ë¡œ ì¶”ê°€ í•¨
	ë³€ìˆ˜ ì¶”ê°€ í–ˆëŠ”ë° ì •í™•ë„ì˜ ë³€í™”ê°€ ì—†ìœ¼ë©´ stop
3. Backward Elimination
	ë³€ìˆ˜ ë‹¤ ë„£ê³  ì‹œì‘ í•˜ë‚˜ì”© ì œê±°
	R^2ê°’ì´ ë³€í™” ì—†ì„ ë•Œ stop
4. Stepwise Selection
	 2,3ì„ ë²ˆê°ˆì•„ ê°€ë©° ê°™ì´ ì”€

### Embedded Method(Penalty Term)

- ì¥ì  
	- Wrapper Methodì™€ ê°™ì´ Featuresì˜ ìƒí˜¸ì‘ìš©ì„ ê³ ë ¤í•¨ 
	- ë‹¤ë¥¸ ë°©ë²• ë³´ë‹¤ ìƒëŒ€ì ìœ¼ë¡œ ì‹œê°„ì„ Saveí•  ìˆ˜ ìˆìŒ 
	- Modelì´ Trainí•˜ë©´ì„œ Featureì˜ Subsetì„ ì°¾ì•„ê°
1. [Ridge Regression](https://code7ssage.github.io/key_terms/Ridge-Regression/)
	ì‹¤ìŠµ:[4-1. Linear regression](https://code7ssage.github.io/code_file/4-1.-Linear-regression/), [4-2. Regularized Model-Ridge Code](https://code7ssage.github.io/code_file/4-2.-Regularized-Model-Ridge-Code/)
2. [LASSO Regression](https://code7ssage.github.io/key_terms/LASSO-Regression/)
- Ridgeì™€ LASSO ëª¨ë‘ tê°€ ì‘ì•„ì§ì— ë”°ë¼ (Î» ê°€ ì»¤ì§ì— ë”°ë¼) ëª¨ë“  ê³„ìˆ˜ì˜ í¬ê¸°ê°€ ê°ì†Œí•¨
- Ridge and Lasso ì¥ë‹¨ì 
	ì‹¤ìŠµ: [5. Regularized Model-LASSO Code](https://code7ssage.github.io/code_file/5.-Regularized-Model-LASSO-Code/)
	![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240104145805.png?raw=true)
3. [ElasticNet](https://code7ssage.github.io/key_terms/ElasticNet/)
	ì‹¤ìŠµ: [6. Regularized Model-ElasticNet Code](https://code7ssage.github.io/code_file/6.-Regularized-Model-ElasticNet-Code/)