---
layout: post
title: objective
---

 -1. **Huber 손실 함수 (Huber)**:
    - Huber 손실 함수는 제곱 오차 손실과 절대 값 오차 손실의 조합입니다.
    - 오차가 작은 경우에는 제곱 오차를 사용해 민감하게 반응하고, 오차가 큰 경우에는 절대 값 오차를 사용해 이상치에 덜 민감하게 반응합니다.
    - 이는 오차에 대한 손실의 증가율이 오차가 커지면서 줄어들기 때문에, 이상치에 강건한(robust) 회귀 모델을 만들기에 적합합니다.
2. **Fair 손실 함수 (Fair)**:
    - Fair 손실 함수는 이상치에 강건한 또 다른 회귀 손실 함수입니다.
    - 이 함수는 절대 오차에 비례하지만, 오차가 커질수록 손실의 증가율이 감소합니다.
    - Fair 손실은 오차가 클 때 Huber 손실보다 더 부드러운 페널티를 적용합니다.
3. **포아송 손실 함수 (Poisson)**:
    - 포아송 회귀는 카운트 데이터(예: 어떤 이벤트의 발생 횟수)를 예측하는 데 적합한 모델입니다.
    - 이 손실 함수는 포아송 분포를 가정하며, 예측값이 항상 양수이고 정수일 필요는 없습니다.
    - 예를 들어, 웹사이트 방문 횟수 예측이나 콜 센터의 전화 수 예측 등에 사용됩니다.
4. **분위수 손실 함수 (Quantile)**:
    - 분위수 회귀는 중앙값, 사분위수 등과 같은 데이터의 특정 분위수를 예측하는 데 사용됩니다.
    - 이 방법은 데이터의 평균값 또는 중앙값만을 예측하는 것이 아니라, 분포 전체를 예측하는 데 도움이 됩니다.
    - 예를 들어, 주택 가격의 중간값 또는 특정 백분위수를 예측하는 데 사용할 수 있습니다.
5. **감마 손실 함수 (Gamma)**:
    - 감마 회귀는 주로 양수 값을 가지며 연속적인 데이터를 위한 것입니다.
    - 이는 감마 분포를 따르는 데이터에 적합하며, 대표적으로 보험금, 병원 체류 기간, 서비스 대기 시간 등이 있습니다.
    - 감마 손실은 예측값이 항상 양수가 되어야 하는 경우에 유용하며, 오차가 클 때 더 큰 패널티를 부여합니다.
6. **트위디 손실 함수 (Tweedie)**:
    - 트위디 회귀는 감마, 포아송, 정규 분포 등 여러 분포의 특성을 일반화한 것입니다.
    - 이는 연속적이거나 카운트 기반의 데이터에 사용할 수 있으며, 특히 0이 많은 데이터에 적합합니다.
    - 예를 들어, 클레임 데이터나 총수익 예측 등에 사용될 수 있습니다.
7. **다중 클래스 OVA (Multiclassova)**:
    - Multiclassova는 One-vs-All (OvA) 방식의 다중 클래스 분류를 의미합니다.
    - 각 클래스에 대해 별도의 이진 분류 문제를 설정하여, 각 클래스가 대상 클래스인지 아닌지를 분류합니다.
    - 이 방법은 각 클래스 간의 불균형을 다루는 데 효과적일 수 있습니다.
8. **크로스 엔트로피 (Cross Entropy)**:
    - 크로스 엔트로피 손실은 분류 문제에 주로 사용됩니다.
    - 이는 모델의 예측 확률 분포와 실제 레이블의 확률 분포 간의 차이를 측정합니다.
    - 이 손실 함수는 두 확률 분포가 얼마나 잘 일치하는지를 평가하며, 주로 이진 또는 다중 클래스 분류 문제에 사용됩니다.
9. **크로스 엔트로피 람다 (Cross Entropy Lambda)**:
    - "cross_entropy_lambda" 손실 함수는 순위 학습 문제에 사용됩니다.
    - 이는 기존의 크로스 엔트로피 손실 함수를 확장하여, 특정 아이템 쌍(pair) 간의 순위 관계를 고려합니다.
    - 람다 접근 방식은 잘못 순위가 매겨진 아이템 쌍에 더 큰 가중치를 부여하여, 순위의 정확도를 높이는 데 도움을 줍니다.
10. **람다랭크 (LambdaRank)**:
    - "lambdarank"는 순위 학습 알고리즘 중 하나로, 검색 엔진 결과와 같은 순위 매김 문제에 주로 사용됩니다.
    - 이 방법은 각 아이템 쌍의 순위 오류에 따라 그라디언트를 조정하며, 순위 메트릭(예: NDCG)의 최적화를 목표로 합니다.
    - LambdaRank는 순위를 결정하는 데 중요한 요소들을 학습하는 데 효과적입니다.
11. **랭크 XE-nDCG (Rank XEnDCG)**:
    - "rank_xendcg"는 또 다른 순위 학습 손실 함수입니다.
    - 이는 특히 정규화된 할인 누적 이득(Normalized Discounted Cumulative Gain, nDCG)을 최적화하는 데 집중합니다.
    - 이 손실 함수는 검색 엔진 최적화나 추천 시스템에서 중요한 순위를 결정하는 데 사용됩니다.
12. **별칭: 목적 유형 (Aliases: Objective Type)**:
    - "aliases: objective_type"는 특정 손실 함수나 목적 함수의 다른 이름을 의미합니다.
    - 프로그래밍 시 다양한 이름으로 동일한 손실 함수를 참조할 수 있으므로, 사용자가 더 쉽게 해당 함수를 식별하고 사용할 수 있게 합니다.
    - 예를 들어, "regression" 대신 "objective_type"이라는 이름을 사용할 수 있습니다.
13. **app (Application)**:
    - "app" 또는 "application"은 주로 LightGBM과 같은 라이브러리에서 사용되며, 모델이 해결하고자 하는 문제의 유형을 정의합니다.
    - 이는 `objective` 파라미터와 유사하게 사용될 수 있으며, 예를 들어 회귀(regression), 이진 분류(binary classification), 다중 클래스 분류(multiclass classification) 등의 문제 유형을 지정할 때 사용됩니다.
    - "app" 또는 "application"을 통해 사용자는 모델이 특정 유형의 데이터를 어떻게 처리할지 결정할 수 있습니다.
14. **loss (손실 함수)**:
    - "loss"는 모델이 학습하는 동안 최소화하려고 하는 손실 함수를 의미합니다.
    - 손실 함수는 모델의 예측값과 실제값 간의 차이를 수치적으로 나타내며, 이를 최소화함으로써 모델의 성능을 향상시킵니다.
    - 다양한 유형의 손실 함수가 있으며, 이는 회귀, 분류, 순위 매김 등 특정 문제 유형에 따라 달라질 수 있습니다.
    - 예를 들어, 회귀 문제에서는 평균 제곱 오차(MSE)나 평균 절대 오차(MAE)가 사용될 수 있고, 분류 문제에서는 크로스 엔트로피 같은 손실 함수가 사용됩니다.