---
title: 2 3. Explainable method
categories:
  - machine_learning
---

# Black Box
- **내부 구조나 작동 원리를 모르더라도 입력과 출력**을 할 수 있는 장치나 회로, 또는 과정 
- 여객기, 수송기와 같은 항공기 안에 비치하는 데이터 자동 기록 장치. 비행 기록 장치와 조종실 음성기록 장치가 들어 있음, 사고가 났을 때 그 **원인을 밝히는데 중요한 구실**을 함
	![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240109120305.png?raw=true)
- performance가 오르면 explainability가 낮아짐
	- deep learning-> per은 높지만 exp가 낮음
	- linear model-> exp는 높지만 per이 낮음
	- Model Complexity가 높은 (해석력이 낮은) Model에 대해 해석을 얻으려는 연구가 많이 이루어짐
- **eXplainable Artificial Intelligence (XAI)**
	![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240109120530.png?raw=true)
- Interpretable Models
	- Linear Regression, Logistic Regression, Generalized Linear Models, Generalized Additive Models
		- Generalized Linear Models: 종속변수의 분포를 여러 분포로 확장
			![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240109121252.png?raw=true)
		- Generalized Additive Models: 비선형 관계도 학습가능
			![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240109121333.png?raw=true)
	- Decision Tree, Naïve Bayes Classifier, K-Nearest Neighbors(KNN) 
		- Naïve Bayes Classifier: P(AㅣB)사용
			![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240109121455.png?raw=true)
	- Local Model-Agnostic Methods : **LIME, SHAP**
# Global vs Local Interpretability
| Global | Local |
| ---- | ---- |
| 종속변수 Y 전체 | 특정 종속변수 Y(Locality) |
| 종속변수 Y 영향을 미치는 중요도 | 특정 종속변수 Y에 영향을 미치는 중요도 |
| **효율**에 영향을 미치는 중요도 | **저효율**에 영향을 미치는 중요도 |
| **공부**에 영향을 미치는 중요도 | **고득점**에 영향을 미치는 중요도 |
| **운전**에 영향을 미치는 중요도 | **고속도로 운전**에 영향을 미치는 중요도 |
- 기존 분석의 중요인자 추출 기법은 전체 데이터를 대변하는 중요 인자를 추출함 
- **데이터 분석의 목적에서 특정 Y(Local, 고효율) 군을 결정 짓는 중요 인자를 추출할 수 있음
- 더 나아가 0.01%(불량 등) 데이터를 결정 짓는 중요 인자를 추출 
- 전체 Y를 대변하는 중요 인자(Global Interpretability)와 특정 데이터에 대한 중요 인자(Local Interpretability)는 다른 결과를 불러올 수 있음 
- 특정 Y(내가 원하는 데이터)에 대한 해석력을 얻기 위해서는 **Black Box Model을 열어 봐야함 
- Interpretable Machine Learning(IML)을 통해 Black Box Model을 열어 봄
	![image](https://github.com/code7ssage/code7ssage.github.io/blob/master/assets/attached%20file/Pasted%20image%2020240109122225.png?raw=true)

# 그래서 black box어떻게 해석해?
-[LIME](https://code7ssage.github.io/LIME//)
-[SHAP](https://code7ssage.github.io/SHAP//)